def generator_model():
    
	model = Sequential()
    #连接函数：把括号内的函数连接起来一次执行，配合add 添加执行项
	model.add(Dense(input_dim=1000, output_dim=1024))
    #Dense，生成全连接层输入1000个数据，输出1024个数据，全连接层类似n元一次函数y1=n1x1+n2x2.....+n.x.输入1000个x输出1024个y
	model.add(Activation('tanh'))
    #激活函数tanh：输入上一层的y，输出一个相应在（-1，1）的值
	model.add(Dense(128 * 8 * 8))
    #一个（8，8，128）的 数据
	model.add(BatchNormalization())
   #对数据进行批标准化，有利于数据优化计算 
	model.add(Activation('tanh'))
    #激活函数tanh：输入上一层的y，输出一个相应在（-1，1）的值
	model.add(Reshape((8, 8, 128), input_shape=(8 * 8 * 128,)))
    #reshpe改变张量的维度  
	model.add(UpSampling2D(size=(4, 4)))
               #进行尺度为（4，4）的上采样  这里类似把一张（8，8，128）的矩阵扩大成（32，32，128）
	model.add(Conv2D(64, (5, 5), padding='same'))
      #64为输出通道数，（5.5）是滤波器的通道数，padding='same'补零 确保输出图片大小和输入图片大小一样
	model.add(Activation('tanh'))
    
	model.add(UpSampling2D(size=(2, 2)))
    #上采样   （32，32）编成（64，64）
	model.add(Conv2D(3, (5, 5), padding='same'))
    #变成3通道  还原成一张图片的大小三通道（64，64，128）
	model.add(Activation('tanh'))
    
return model





def discriminator_model():
    
	model = Sequential()
   #连接函数：把括号内的函数连接起来一次执行，配合add 添加执行项 
	model.add(Conv2D(64, (5, 5), padding='same', input_shape=(64, 64, 3)))
    #进行卷积核（5，5）的卷积，输出维度（64，64，64）  
	model.add(Activation('tanh'))
    #激活函数
	model.add(MaxPooling2D(pool_size=(2, 2)))
   #maxpooling：最大池化， 类似将图片缩小一倍
	model.add(Conv2D(128, (5, 5)))
              #卷积  输出维度（28，28，128）  
	model.add(Activation('tanh'))
    #激活函数
	model.add(MaxPooling2D(pool_size=(2, 2)))
   #池化成（14，14，128）  
	model.add(Flatten())
    #flatten把（14，14，128）展开成一维数据14*14*128
	model.add(Dense(1024))
    将14*14*128  映射成1024个数据
	model.add(Activation('tanh'))
    #激活函数
	model.add(Dense(1))
     #全连接层
	model.add(Activation('sigmoid'))
    #激活函数：输出在（0，1）之间
return model




# 随机生成的1000维，BATCA_SIZE,就是你一次性输入的图片的个数，相当于你一次训练五张图片，所以需要五个1000维向量
noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 1000))
 


# X_train是训练的图片数据，这里取出一个batchsize的图片用于训练，这个是真图（64张）相当于在真实的图片中读取BATCH_size张图片
image_batch = X_train[index * BATCH_SIZE:(index + 1) * BATCH_SIZE]
 


# 这里是经过生成器生成的假图
  生成器生成BATCH_SIZE张图片
generated_images = generator_model.predict(noise, verbose=0)
 


# 将真图与假图进行拼接,把真图和假图放入一个列表中     
X = np.concatenate((image_batch, generated_images))
 


# 与X对应的标签，前64张图为真，标签是1，后64张图是假图，标签为0，类似（1，1，1，1，1，0，0，0，0，0）省略一部分
 y = [1] * BATCH_SIZE + [0] * BATCH_SIZE
 
 
# 把真图与假图的拼接训练数据1送入判别器进行训练判别器的准确度

d_loss = discriminator_model.train_on_batch(X, y)   #这里就是损失函数，只不过他调用人家写好了的损失函数

原理就是d_loss= argmin（y真-y假）的平方
  真图减假图的平方的值越小  说明生成器的生成的图片越逼近真是的图片。
